# -*- coding: utf-8 -*-
"""Maksi_Roi_finalProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CN8gNWmoVMnl73CD3B_GPPSVUtQtylvl

# Decision Tree Tutorial

In this tutorial, we work with decision tree.

# שלב 1 - ביצוע רגרסיה

Registering to Kaggle API
"""

import json
import os

!mkdir /root/.kaggle/
# Installing the Kaggle package

#Important Note: complete this with your own key - after running this for the first time remmember to **remove** your API_KEY
api_token = {"username":"maksikr","key":"7fede70b8416229b1387e8d5d4da2273"}

# creating kaggle.json file with the personal API-Key details
# You can also put this file on your Google Drive

with open('/root/.kaggle/kaggle.json', 'w') as file:
  json.dump(api_token, file)
!chmod 600 /root/.kaggle/kaggle.json

"""Downloading the Heart Attack dataset"""

# יצירת התיקייה להורדת הדאטאסט
!mkdir -p ./datasets/heart-attack-analysis

# הורדת הדאטאסט מתוך Kaggle ופריסתו
!kaggle datasets download rashikrahmanpritom/heart-attack-analysis-prediction-dataset -p ./datasets/heart-attack-analysis
!unzip ./datasets/heart-attack-analysis/*.zip -d ./datasets/heart-attack-analysis/

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.preprocessing import KBinsDiscretizer
from sklearn.metrics import accuracy_score, classification_report
from sklearn.tree import plot_tree
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor

"""טעינה של הדאטא-סט לתוך התכנית"""

# קריאת הדאטאסט לתוך DataFrame
df = pd.read_csv('./datasets/heart-attack-analysis/heart.csv')

# הצגת השורות הראשונות ונתונים כללים
print(df.head())
df.describe()

"""נחשב מטריצת קולורציה כדי לבדוק את התוצאות, לפי זה נדע מאיזה עמודות כדאי להפטר בריגרסיה."""

# חישוב מטריצת הקורלציה
correlation_matrix = df.corr()

# הצגת הקורלציה של כל עמודה עם עמודת 'age'
age_correlation = correlation_matrix['age'].sort_values(ascending=False)
print("Correlation with 'age':")
print(age_correlation)

"""נבחין ונסתכל האם יש ערכים חסרים בדאטא-סט שבחרנו"""

missing_values = df.isnull().sum()
print(missing_values)

"""נבצע שני שלבים:
1. נמחק את העמודות בעלות קולורציה נמוכה שאין לנו צורך בהם ברגרסור.
2. נחלק את הדאטסט לעמודת הטרגט שלנו ולשאר הפיצ'רים
"""

# מחיקת פיצ'רים עם קורלציה נמוכה לגיל
columns_to_remove = ['thall', 'cp', 'sex', 'restecg', 'slp', 'output']
df_reduced = df.drop(columns=columns_to_remove)

# Display the first few rows of the reduced DataFrame to verify
df_reduced.head()

# Saving the target class ('output' column)
target_class = df_reduced['age']

# Saving all the features except the target class
features = df_reduced.drop('age', axis=1)

"""נחלק לסט-אימון ולסט-מבחן בתצורה של 80%-20%."""

# Divide the data into training and test sets (80%-20%)
X_train, X_test, y_train, y_test = train_test_split(features, target_class, test_size=0.2, random_state=42)

# Display the shapes of the resulting datasets to confirm
X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""נבנה את הרגרסור כעץ החלטה, ונאמן את המודל על קבוצת האימון"""

# יצירת רגרסור עץ החלטה
regressor = DecisionTreeRegressor(max_depth = 5,min_samples_leaf=15,random_state=1)

# אימון המודל על קבוצת האימון
regressor.fit(X_train, y_train)

"""כעת נריץ את התחזית על קבוצת הבדיקה, מיד אחרי זה נבדוק את מדדי הדיוק כדי לראות כמה אנחנו קרובים ומדוייקים."""

# תחזית על קבוצת הבדיקה
y_pred = regressor.predict(X_test)

# חישוב מדדי דיוק
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# הצגת התוצאות
print(f"Mean Squared Error (MSE): {mse}")
print(f"R^2 Score: {r2}")

"""נציג את העץ של הרגרסיה"""

plt.figure(figsize=(20,10))
plot_tree(regressor, filled=True, feature_names=features.columns, rounded=True)
plt.show()

"""נבצע את אותו התהליך ממקודם, עם רגרסיה של עץ החלטה - אבל הפעם ננרמל 3 עמודות מהדטאסט שלנו כדי לראות האם יש הבדל בתוצאות שקיבלנו.

"""

# מחיקת פיצ'רים עם קורלציה נמוכה לגיל
columns_to_remove = ['thall', 'cp', 'sex', 'restecg', 'slp', 'output']
df_reduced_1 = df.drop(columns=columns_to_remove)

scaler = MinMaxScaler()
df_reduced_1[['thalachh', 'trtbps', 'chol']] = scaler.fit_transform(df_reduced_1[['thalachh', 'trtbps', 'chol']])

# הצגת מספר השורות הראשונות לאימות
print(df_reduced_1.head())

# שמירת עמודת המטרה (גיל)
target_class1 = df_reduced_1['age']

# שמירת כל הפיצ'רים למעט המטרה
features1 = df_reduced_1.drop('age', axis=1)

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train1, X_test1, y_train1, y_test1 = train_test_split(features1, target_class1, test_size=0.2, random_state=42)

# יצירת רגרסור עץ החלטה
regressor = DecisionTreeRegressor(max_depth = 5,min_samples_leaf=15,random_state=1)

# אימון המודל על קבוצת האימון
regressor.fit(X_train1, y_train1)

# תחזית על קבוצת הבדיקה
y_pred1 = regressor.predict(X_test1)

# חישוב מדדי דיוק
mse = mean_squared_error(y_test1, y_pred1)
r2 = r2_score(y_test1, y_pred1)

# הצגת התוצאות
print(f"Mean Squared Error (MSE): {mse}")
print(f"R^2 Score: {r2}")

# ויזואליזציה של עץ ההחלטה
plt.figure(figsize=(20,10))
plot_tree(regressor, filled=True, feature_names=features.columns, rounded=True)
plt.show()

"""נריץ רגרסיה לינארית ונראה גם פה את התוצאות"""

# מחיקת פיצ'רים עם קורלציה נמוכה לגיל
columns_to_remove = ['thall', 'cp', 'sex', 'restecg', 'slp', 'output']
df_reduced_2 = df.drop(columns=columns_to_remove)

# נורמליזציה של העמודות 'thalachh', 'trtbps', ו-'chol'
scaler = MinMaxScaler()
df_reduced_2[['thalachh', 'trtbps', 'chol']] = scaler.fit_transform(df_reduced_2[['thalachh', 'trtbps', 'chol']])

# הצגת מספר השורות הראשונות לאימות
print(df_reduced_2.head())

# שמירת עמודת המטרה (גיל)
target_class2 = df_reduced_2['age']

# שמירת כל הפיצ'רים למעט המטרה
features2 = df_reduced_2.drop('age', axis=1)

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train, X_test, y_train, y_test = train_test_split(features2, target_class2, test_size=0.2, random_state=42)

# יצירת מודל רגרסיה לינארית
linear_regressor = LinearRegression()

# אימון המודל על קבוצת האימון
linear_regressor.fit(X_train, y_train)

# תחזית על קבוצת הבדיקה
y_pred = linear_regressor.predict(X_test)

# חישוב מדדי דיוק
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# הצגת התוצאות
print(f"Mean Squared Error (MSE): {mse}")
print(f"R^2 Score: {r2}")

# הצגת המקדם של כל פיצ'ר
coefficients = pd.DataFrame(linear_regressor.coef_, features.columns, columns=['Coefficient'])
print(coefficients)

# אם תרצה להציג את התחזיות מול הערכים האמיתיים:
plt.scatter(y_test, y_pred)
plt.xlabel("Actual Age")
plt.ylabel("Predicted Age")
plt.title("Actual vs Predicted Age")
plt.show()

"""נריץ רגרסיה ליניארית והפעם עם נורמליזציה כדי לראות את ההבדלים אם קיימים בתוצאות."""

# שמירת עמודת המטרה (גיל)
target_class2 = df_reduced['age']

# שמירת כל הפיצ'רים למעט המטרה
features2 = df_reduced.drop('age', axis=1)

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train, X_test, y_train, y_test = train_test_split(features2, target_class2, test_size=0.2, random_state=42)

# יצירת מודל רגרסיה לינארית
linear_regressor = LinearRegression()

# אימון המודל על קבוצת האימון
linear_regressor.fit(X_train, y_train)

# תחזית על קבוצת הבדיקה
y_pred = linear_regressor.predict(X_test)

# חישוב מדדי דיוק
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# הצגת התוצאות
print(f"Mean Squared Error (MSE): {mse}")
print(f"R^2 Score: {r2}")

# הצגת המקדם של כל פיצ'ר
coefficients = pd.DataFrame(linear_regressor.coef_, features.columns, columns=['Coefficient'])
print(coefficients)

# אם תרצה להציג את התחזיות מול הערכים האמיתיים:
plt.scatter(y_test, y_pred)
plt.xlabel("Actual Age")
plt.ylabel("Predicted Age")
plt.title("Actual vs Predicted Age")
plt.show()

"""נריץ גם עוד רגרסור נוסף של רנדום-פורסט כדי לראות הבדלים"""

# מחיקת פיצ'רים עם קורלציה נמוכה לגיל
columns_to_remove = ['thall', 'cp', 'sex', 'restecg', 'slp', 'output']
df_reduced_3 = df.drop(columns=columns_to_remove)

# נורמליזציה של העמודות 'thalachh', 'trtbps', ו-'chol'
scaler = MinMaxScaler()
df_reduced_3[['thalachh', 'trtbps', 'chol']] = scaler.fit_transform(df_reduced_3[['thalachh', 'trtbps', 'chol']])

# הצגת מספר השורות הראשונות לאימות
print(df_reduced_3.head())

# שמירת עמודת המטרה (גיל)
target_class3 = df_reduced_3['age']

# שמירת כל הפיצ'רים למעט המטרה
features3 = df_reduced_3.drop('age', axis=1)

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train, X_test, y_train, y_test = train_test_split(features3, target_class3, test_size=0.2, random_state=42)

# יצירת המודל של Random Forest Regression
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)

# אימון המודל על קבוצת האימון
rf_regressor.fit(X_train, y_train)

# ביצוע תחזיות על קבוצת הבדיקה
y_pred = rf_regressor.predict(X_test)

# חישוב מדדי דיוק
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# הצגת התוצאות
print(f"Mean Squared Error (MSE): {mse}")
print(f"R^2 Score: {r2}")

# ציור הגרף
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Age')
plt.ylabel('Predicted Age')
plt.title('Actual vs Predicted Age')
plt.show()

"""כעת נריץ את הרגרסור ללא ביצוע הנורמליזציה ונבחן את התוצאות ואת השוני בתוצאות שיצאו לנו"""

# שמירת עמודת המטרה (גיל)
target_class2 = df_reduced['age']

# שמירת כל הפיצ'רים למעט המטרה
features2 = df_reduced.drop('age', axis=1)

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train, X_test, y_train, y_test = train_test_split(features2, target_class2, test_size=0.2, random_state=42)

# יצירת המודל של Random Forest Regression
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)

# אימון המודל על קבוצת האימון
rf_regressor.fit(X_train, y_train)

# ביצוע תחזיות על קבוצת הבדיקה
y_pred = rf_regressor.predict(X_test)

# חישוב מדדי דיוק
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# הצגת התוצאות
print(f"Mean Squared Error (MSE): {mse}")
print(f"R^2 Score: {r2}")

# ציור הגרף
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Age')
plt.ylabel('Predicted Age')
plt.title('Actual vs Predicted Age')
plt.show()

"""# שלב 2 - נבצע דיסקרטיזציה על עמודת הגיל שעליה הרצנו ריגרסיה

מחיקת פיצ'רים בעלי קולורציה נמוכה כפי שעשינו ברגרסיה + נורמליזציה של העמודות המספריות + דיסקטרזציה של עמודת הגיל לפני קטגוריות מותאמות לדטאסט
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

# מחיקת פיצ'רים עם קורלציה נמוכה לגיל
columns_to_remove = ['thall', 'cp', 'sex', 'restecg', 'slp', 'output']
df_reduced_3 = df.drop(columns=columns_to_remove)

# נורמליזציה של העמודות 'thalachh', 'trtbps', ו-'chol'
scaler = MinMaxScaler()
df_reduced_3[['thalachh', 'trtbps', 'chol']] = scaler.fit_transform(df_reduced_3[['thalachh', 'trtbps', 'chol']])

# דיסקרטיזציה של עמודת הגיל
df_reduced_3['age_group'] = pd.cut(df_reduced_3['age'],
                                   bins=[27, 40, 55, 77],
                                   labels=['29-40', '41-55', '56-77'])

# מחיקת עמודת הגיל המקורית לאחר הדיסקרטיזציה
df_reduced_3 = df_reduced_3.drop(columns=['age'])

# טיפול בערכים חסרים - מחיקת שורות עם ערכים חסרים
df_reduced_3 = df_reduced_3.dropna()

# הצגת מספר השורות הראשונות לאימות
print(df_reduced_3.head())

"""הגדרה של עמודת החיזוי ושאר עמודות הפיצ'רים, בנוסף נחלק לקבוצות מבחן ובדיקה"""

# הגדרת הפיצ'רים והמטרות
features = df_reduced_3.drop('age_group', axis=1)
target_class = df_reduced_3['age_group']

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train, X_test, y_train, y_test = train_test_split(features, target_class, test_size=0.2, random_state=42)

"""יצירת מודל קלסיפקציה מסוג עץ החלטה וחיזוי"""

# יצירת המודל של Decision Tree Classifier
clf = DecisionTreeClassifier(max_depth=4,min_samples_leaf=15, random_state=1)

# אימון המודל על קבוצת האימון
clf.fit(X_train, y_train)

# ביצוע תחזיות על קבוצת הבדיקה
y_pred = clf.predict(X_test)

"""ויזואלזציה של עץ ההחלטה"""

# ויזואליזציה של עץ ההחלטה
plt.figure(figsize=(20,10))
plot_tree(clf, filled=True, feature_names=features.columns, class_names=clf.classes_, rounded=True)
plt.show()

"""הצגת הדיוק של המסווג הספציפי והצגת נתונים רלוונטים כדי לבדוק את יעילות המודל המאומן"""

# חישוב ה Accuracy
accuracy = accuracy_score(y_test, y_pred)
accuracy

"""כעת נחשב את הדיוק של המודל על קבוצת האימון, לאחר מכן נחשב את הדיוק של המודל על קבוצת הבדיקה. נבדוק את ההבדל וכך נבין האם אנחנו סובלים מאובר-פיטינג"""

print(df_reduced_3['age_group'].value_counts(normalize=True))
# חישוב דיוק המודל על קבוצת האימון
train_accuracy = clf.score(X_train, y_train)

# חישוב דיוק המודל על קבוצת הבדיקה (כבר חושב למעלה כ-accuracy)
test_accuracy = accuracy_score(y_test, y_pred)

print(f"Train Accuracy: {train_accuracy}")
print(f"Test Accuracy: {test_accuracy}")

if train_accuracy > test_accuracy:
  print("The classifier suffers from overfitting")
else:
  print("The classifier does not suffers from overfitting")

  import numpy as np
from sklearn.metrics import roc_curve, auc, roc_auc_score
from sklearn.preprocessing import label_binarize

print('Accuracy of Decision Tree-Test:',accuracy_score(y_pred,y_test))
y_prob1 = clf.predict_proba(X_test)

# Calculate ROC AUC for each class
for i in range(len(clf.classes_)):
    roc_auc = roc_auc_score(y_test == clf.classes_[i], y_prob1[:, i])
    print(f"AUC ROC of Decision Tree-Test:{clf.classes_[i]}: {roc_auc}")

"""נבדוק את ה majority class , נראה שהדיוק שיצא לנו אכן גבוה ממנו כדי לוודא שהמודל פועל ביעילות"""

# בדיקת מספר הדוגמאות בכל קבוצה בעמודת המטרה
class_counts = df_reduced_3['age_group'].value_counts()

# מציאת הקבוצה עם המספר הגבוה ביותר (ה-Majority Class)
majority_class = class_counts.idxmax()
majority_class_count = class_counts.max()

# חישוב אחוז ה-Majority Class
total_samples = len(df_reduced_3)
majority_class_percentage = (majority_class_count / total_samples) * 100

print(f"Majority Class: {majority_class}")
print(f"Majority Class Count: {majority_class_count}")
print(f"Majority Class Percentage: {majority_class_percentage:.2f}%")

"""כעת נריץ את אותו עץ החלטה אבל הפעם נעשה oversampling כי שמנו לב שהנתונים לא מחולקים בצורה שווה ואף לגמרי לא שיוויונית בסט שלנו"""

import pandas as pd
from sklearn.utils import resample

# ביצוע Oversampling לקטגוריות הקטנות
df_majority_56_77 = df_reduced_3[df_reduced_3['age_group'] == '56-77']
df_majority_41_55 = df_reduced_3[df_reduced_3['age_group'] == '41-55']
df_minority_29_40 = df_reduced_3[df_reduced_3['age_group'] == '29-40']

df_minority_29_40_upsampled = resample(df_minority_29_40,
                                       replace=True,  # דגימה עם החזרה
                                       n_samples=len(df_majority_56_77),  # מספר הדוגמאות בקטגוריה הגדולה ביותר
                                       random_state=42)

df_majority_41_55_upsampled = resample(df_majority_41_55,
                                       replace=True,
                                       n_samples=len(df_majority_56_77),
                                       random_state=42)

# איחוד חזרה של כל הקטגוריות לאחר ה-oversampling
df_upsampled = pd.concat([df_majority_56_77, df_majority_41_55_upsampled, df_minority_29_40_upsampled])

# הגדרת הפיצ'רים והמטרות
features = df_upsampled.drop('age_group', axis=1)
target_class = df_upsampled['age_group']

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train, X_test, y_train, y_test = train_test_split(features, target_class, test_size=0.2, random_state=42)

# יצירת המודל של Decision Tree Classifier
clf = DecisionTreeClassifier(max_depth=4, min_samples_leaf=15, random_state=1)

# אימון המודל על קבוצת האימון
clf.fit(X_train, y_train)

# ביצוע תחזיות על קבוצת הבדיקה
y_pred = clf.predict(X_test)

# ציור עץ ההחלטה
plt.figure(figsize=(20,10))
plot_tree(clf, feature_names=X_train.columns, class_names=clf.classes_, filled=True)
plt.show()

print(df_reduced_3['age_group'].value_counts(normalize=True))
# חישוב דיוק המודל על קבוצת האימון
train_accuracy = clf.score(X_train, y_train)

# חישוב דיוק המודל על קבוצת הבדיקה (כבר חושב למעלה כ-accuracy)
test_accuracy = accuracy_score(y_test, y_pred)

print(f"Train Accuracy: {train_accuracy}")
print(f"Test Accuracy: {test_accuracy}")

if train_accuracy > test_accuracy:
  print("The classifier suffers from overfitting")
else:
  print("The classifier does not suffers from overfitting")

  import numpy as np
from sklearn.metrics import roc_curve, auc, roc_auc_score
from sklearn.preprocessing import label_binarize

print('Accuracy of Decision Tree-Test:',accuracy_score(y_pred,y_test))
y_prob1 = clf.predict_proba(X_test)

# Calculate ROC AUC for each class
for i in range(len(clf.classes_)):
    roc_auc = roc_auc_score(y_test == clf.classes_[i], y_prob1[:, i])
    print(f"AUC ROC of Decision Tree-Test:{clf.classes_[i]}: {roc_auc}")

"""בניית מסווג לינארי לפי הדיסקרטיזציה שבנינו על עמודת הגיל, אימון המודל על קבוצת האימון וביצוע תחזית על קבוצת הבדיקה."""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# יצירת המודל של Logistic Regression Classifier
clf = LogisticRegression(random_state=1, max_iter=200)

# אימון המודל על קבוצת האימון
clf.fit(X_train, y_train)

# ביצוע תחזיות על קבוצת הבדיקה
y_pred = clf.predict(X_test)

# חישוב ה-Accuracy
accuracy = accuracy_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")

"""נחשב את דיוק המודל על קבוצת האימון, נחשב את דיוק המודל על קבוצת הבדיקה ולאחר מכן נעשה השוואה כדי לראות האם הוא סובל מאובר-פיטינג"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, roc_auc_score
import numpy as np

# חישוב ה-ROC Curve עבור כל קטגוריה
plt.figure(figsize=(10, 8))
for i in range(len(clf.classes_)):
    fpr, tpr, _ = roc_curve(y_test == clf.classes_[i], y_prob1[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve of class {clf.classes_[i]} (area = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# חישוב דיוק המודל על קבוצת האימון
y_pred_train = clf.predict(X_train)
accuracy_train = accuracy_score(y_train, y_pred_train)

# חישוב דיוק המודל על קבוצת הבדיקה (כבר חושב למעלה כ-accuracy)
accuracy_test = accuracy_score(y_test, y_pred)

# בדיקה האם המודל סובל מ-overfitting
if accuracy_train > accuracy_test:
    print("The classifier suffers from overfitting")
else:
    print("The classifier does not suffer from overfitting")

# הצגת תוצאות הדיוק
print(f"Train Accuracy: {accuracy_train}")
print(f"Test Accuracy: {accuracy_test}")

print('Accuracy of Decision Tree-Test:',accuracy_score(y_pred,y_test))
y_prob1 = clf.predict_proba(X_test)

# Calculate ROC AUC for each class
for i in range(len(clf.classes_)):
    roc_auc = roc_auc_score(y_test == clf.classes_[i], y_prob1[:, i])
    print(f"AUC ROC of Decision Tree-Test:{clf.classes_[i]}: {roc_auc}")

"""הרצת מסווג ליניארי ללא oversampling"""

# הגדרת הפיצ'רים והמטרות
features = df_reduced_3.drop('age_group', axis=1)
target_class = df_reduced_3['age_group']

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train, X_test, y_train, y_test = train_test_split(features, target_class, test_size=0.2, random_state=42)

# יצירת המודל של Logistic Regression Classifier
clf = LogisticRegression(random_state=1, max_iter=200)

# אימון המודל על קבוצת האימון
clf.fit(X_train, y_train)

# ביצוע תחזיות על קבוצת הבדיקה
y_pred = clf.predict(X_test)

# חישוב ה-Accuracy
accuracy = accuracy_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")

# חישוב דיוק המודל על קבוצת האימון
y_pred_train = clf.predict(X_train)
accuracy_train = accuracy_score(y_train, y_pred_train)

# חישוב דיוק המודל על קבוצת הבדיקה (כבר חושב למעלה כ-accuracy)
accuracy_test = accuracy_score(y_test, y_pred)


# בדיקה האם המודל סובל מ-overfitting
if accuracy_train > accuracy_test:
    print("The classifier suffers from overfitting")
else:
    print("The classifier does not suffer from overfitting")

# הצגת תוצאות הדיוק
print(f"Train Accuracy: {accuracy_train}")
print(f"Test Accuracy: {accuracy_test}")

# חישוב תחזיות הסתברותיות על קבוצת הבדיקה
y_prob1 = clf.predict_proba(X_test)

# חישוב ה-ROC Curve עבור כל קטגוריה
plt.figure(figsize=(10, 8))
for i in range(len(clf.classes_)):
    fpr, tpr, _ = roc_curve(y_test == clf.classes_[i], y_prob1[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve of class {clf.classes_[i]} (area = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# חישוב AUC ROC עבור כל קטגוריה
for i in range(len(clf.classes_)):
    roc_auc = roc_auc_score(y_test == clf.classes_[i], y_prob1[:, i])
    print(f"AUC ROC of Logistic Regression-Test: {clf.classes_[i]}: {roc_auc}")

"""הרצת מסווג Naive Bayse עם ביצוע אובר-סמפלינג"""

import pandas as pd
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score
import matplotlib.pyplot as plt
import numpy as np

# ביצוע Oversampling לקטגוריות הקטנות
df_majority_56_77 = df_reduced_3[df_reduced_3['age_group'] == '56-77']
df_majority_41_55 = df_reduced_3[df_reduced_3['age_group'] == '41-55']
df_minority_29_40 = df_reduced_3[df_reduced_3['age_group'] == '29-40']

df_minority_29_40_upsampled = resample(df_minority_29_40,
                                       replace=True,  # דגימה עם החזרה
                                       n_samples=len(df_majority_56_77),  # מספר הדוגמאות בקטגוריה הגדולה ביותר
                                       random_state=42)

df_majority_41_55_upsampled = resample(df_majority_41_55,
                                       replace=True,
                                       n_samples=len(df_majority_56_77),
                                       random_state=42)

# איחוד חזרה של כל הקטגוריות לאחר ה-oversampling
df_upsampled = pd.concat([df_majority_56_77, df_majority_41_55_upsampled, df_minority_29_40_upsampled])

# הגדרת הפיצ'רים והמטרות
features = df_upsampled.drop('age_group', axis=1)
target_class = df_upsampled['age_group']

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train, X_test, y_train, y_test = train_test_split(features, target_class, test_size=0.2, random_state=42)

# יצירת המודל של Naive Bayes Classifier
clf = GaussianNB()

# אימון המודל על קבוצת האימון
clf.fit(X_train, y_train)

# ביצוע תחזיות על קבוצת הבדיקה
y_pred = clf.predict(X_test)

# חישוב דיוק המודל על קבוצת האימון
train_accuracy = clf.score(X_train, y_train)

# חישוב דיוק המודל על קבוצת הבדיקה
test_accuracy = accuracy_score(y_test, y_pred)

print(f"Train Accuracy: {train_accuracy}")
print(f"Test Accuracy: {test_accuracy}")

# בדיקה האם המודל סובל מ-overfitting
if train_accuracy > test_accuracy:
    print("The classifier suffers from overfitting")
else:
    print("The classifier does not suffer from overfitting")

# חישוב תחזיות הסתברותיות על קבוצת הבדיקה
y_prob1 = clf.predict_proba(X_test)

# חישוב ה-ROC Curve עבור כל קטגוריה
plt.figure(figsize=(10, 8))
for i in range(len(clf.classes_)):
    fpr, tpr, _ = roc_curve(y_test == clf.classes_[i], y_prob1[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve of class {clf.classes_[i]} (area = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve - Naive Bayes')
plt.legend(loc="lower right")
plt.show()

# חישוב AUC ROC עבור כל קטגוריה
for i in range(len(clf.classes_)):
    roc_auc = roc_auc_score(y_test == clf.classes_[i], y_prob1[:, i])
    print(f"AUC ROC of Naive Bayes-Test: {clf.classes_[i]}: {roc_auc}")

"""כעת נבצע את הבדיקה ללא oversampling"""

# הגדרת הפיצ'רים והמטרות
features = df_reduced_3.drop('age_group', axis=1)
target_class = df_reduced_3['age_group']

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train, X_test, y_train, y_test = train_test_split(features, target_class, test_size=0.2, random_state=42)

# יצירת המודל של Naive Bayes Classifier
clf = GaussianNB()

# אימון המודל על קבוצת האימון
clf.fit(X_train, y_train)

# ביצוע תחזיות על קבוצת הבדיקה
y_pred = clf.predict(X_test)

# חישוב דיוק המודל על קבוצת האימון
train_accuracy = clf.score(X_train, y_train)

# חישוב דיוק המודל על קבוצת הבדיקה
test_accuracy = accuracy_score(y_test, y_pred)

print(f"Train Accuracy: {train_accuracy}")
print(f"Test Accuracy: {test_accuracy}")

# בדיקה האם המודל סובל מ-overfitting
if train_accuracy > test_accuracy:
    print("The classifier suffers from overfitting")
else:
    print("The classifier does not suffer from overfitting")

# חישוב תחזיות הסתברותיות על קבוצת הבדיקה
y_prob1 = clf.predict_proba(X_test)

# חישוב ה-ROC Curve עבור כל קטגוריה
plt.figure(figsize=(10, 8))
for i in range(len(clf.classes_)):
    fpr, tpr, _ = roc_curve(y_test == clf.classes_[i], y_prob1[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve of class {clf.classes_[i]} (area = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve - Naive Bayes')
plt.legend(loc="lower right")
plt.show()

# חישוב AUC ROC עבור כל קטגוריה
for i in range(len(clf.classes_)):
    roc_auc = roc_auc_score(y_test == clf.classes_[i], y_prob1[:, i])
    print(f"AUC ROC of Naive Bayes-Test: {clf.classes_[i]}: {roc_auc}")

"""הרצת מודל Random-Forest עם ביצוע אובר-סמפלינג"""

import pandas as pd
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score
import matplotlib.pyplot as plt
import numpy as np

# ביצוע Oversampling לקטגוריות הקטנות
df_majority_56_77 = df_reduced_3[df_reduced_3['age_group'] == '56-77']
df_majority_41_55 = df_reduced_3[df_reduced_3['age_group'] == '41-55']
df_minority_29_40 = df_reduced_3[df_reduced_3['age_group'] == '29-40']

df_minority_29_40_upsampled = resample(df_minority_29_40,
                                       replace=True,  # דגימה עם החזרה
                                       n_samples=len(df_majority_56_77),  # מספר הדוגמאות בקטגוריה הגדולה ביותר
                                       random_state=42)

df_majority_41_55_upsampled = resample(df_majority_41_55,
                                       replace=True,
                                       n_samples=len(df_majority_56_77),
                                       random_state=42)

# איחוד חזרה של כל הקטגוריות לאחר ה-oversampling
df_upsampled = pd.concat([df_majority_56_77, df_majority_41_55_upsampled, df_minority_29_40_upsampled])

# הגדרת הפיצ'רים והמטרות
features = df_upsampled.drop('age_group', axis=1)
target_class = df_upsampled['age_group']

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train, X_test, y_train, y_test = train_test_split(features, target_class, test_size=0.2, random_state=42)

# יצירת המודל של Random Forest Classifier
clf = RandomForestClassifier(n_estimators=70, random_state=42)

# אימון המודל על קבוצת האימון
clf.fit(X_train, y_train)

# ביצוע תחזיות על קבוצת הבדיקה
y_pred = clf.predict(X_test)

# חישוב דיוק המודל על קבוצת האימון
train_accuracy = clf.score(X_train, y_train)

# חישוב דיוק המודל על קבוצת הבדיקה
test_accuracy = accuracy_score(y_test, y_pred)

print(f"Train Accuracy: {train_accuracy}")
print(f"Test Accuracy: {test_accuracy}")

# בדיקה האם המודל סובל מ-overfitting
if train_accuracy > test_accuracy:
    print("The classifier suffers from overfitting")
else:
    print("The classifier does not suffer from overfitting")

# חישוב תחזיות הסתברותיות על קבוצת הבדיקה
y_prob1 = clf.predict_proba(X_test)

# חישוב ה-ROC Curve עבור כל קטגוריה
plt.figure(figsize=(10, 8))
for i in range(len(clf.classes_)):
    fpr, tpr, _ = roc_curve(y_test == clf.classes_[i], y_prob1[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve of class {clf.classes_[i]} (area = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve - Random Forest')
plt.legend(loc="lower right")
plt.show()

# חישוב AUC ROC עבור כל קטגוריה
for i in range(len(clf.classes_)):
    roc_auc = roc_auc_score(y_test == clf.classes_[i], y_prob1[:, i])
    print(f"AUC ROC of Random Forest-Test: {clf.classes_[i]}: {roc_auc}")

# ציור עץ החלטה מתוך היער המאומן
from sklearn.tree import plot_tree

plt.figure(figsize=(20, 10))
plot_tree(clf.estimators_[0], feature_names=X_train.columns, class_names=clf.classes_, filled=True, rounded=True)
plt.show()

"""הרצת מודל random-forest והפעם ללא ביצוע אובר-סמפלינג"""

# הגדרת הפיצ'רים והמטרות
features = df_reduced_3.drop('age_group', axis=1)
target_class = df_reduced_3['age_group']

# חלוקת הנתונים לקבוצות אימון ובדיקה
X_train, X_test, y_train, y_test = train_test_split(features, target_class, test_size=0.2, random_state=42)

# יצירת המודל של Random Forest Classifier
clf = RandomForestClassifier(n_estimators=70, random_state=42)

# אימון המודל על קבוצת האימון
clf.fit(X_train, y_train)

# ביצוע תחזיות על קבוצת הבדיקה
y_pred = clf.predict(X_test)

# חישוב דיוק המודל על קבוצת האימון
train_accuracy = clf.score(X_train, y_train)

# חישוב דיוק המודל על קבוצת הבדיקה
test_accuracy = accuracy_score(y_test, y_pred)

print(f"Train Accuracy: {train_accuracy}")
print(f"Test Accuracy: {test_accuracy}")

# בדיקה האם המודל סובל מ-overfitting
if train_accuracy > test_accuracy:
    print("The classifier suffers from overfitting")
else:
    print("The classifier does not suffer from overfitting")

# חישוב תחזיות הסתברותיות על קבוצת הבדיקה
y_prob1 = clf.predict_proba(X_test)

# חישוב ה-ROC Curve עבור כל קטגוריה
plt.figure(figsize=(10, 8))
for i in range(len(clf.classes_)):
    fpr, tpr, _ = roc_curve(y_test == clf.classes_[i], y_prob1[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve of class {clf.classes_[i]} (area = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve - Random Forest')
plt.legend(loc="lower right")
plt.show()

# חישוב AUC ROC עבור כל קטגוריה
for i in range(len(clf.classes_)):
    roc_auc = roc_auc_score(y_test == clf.classes_[i], y_prob1[:, i])
    print(f"AUC ROC of Random Forest-Test: {clf.classes_[i]}: {roc_auc}")

# ציור עץ החלטה מתוך היער המאומן
from sklearn.tree import plot_tree

plt.figure(figsize=(20, 10))
plot_tree(clf.estimators_[0], feature_names=X_train.columns, class_names=clf.classes_, filled=True, rounded=True)
plt.show()

"""10-fold"""

import pandas as pd
from sklearn.model_selection import cross_val_score, StratifiedKFold, cross_val_predict
from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import label_binarize
import numpy as np

# הגדרת הפיצ'רים והמטרות
features = df_upsampled.drop('age_group', axis=1)
target_class = df_upsampled['age_group']

# בינאריזציה של היעדים לחישוב AUC לכל קטגוריה
classes = target_class.unique()
target_class_bin = label_binarize(target_class, classes=classes)

# הגדרת StratifiedKFold ל-Fold-10
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# מסווגים
classifiers = {
    "Decision Tree": DecisionTreeClassifier(max_depth=4, min_samples_leaf=15, random_state=1),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=200, random_state=42),
    "Naive Bayes": GaussianNB()
}

# אחסון התוצאות
results = {}

# ריצה על כל מסווג
for name, clf in classifiers.items():
    auc_scores = []
    y_prob_all = cross_val_predict(clf, features, target_class, cv=skf, method='predict_proba')

    for i, class_name in enumerate(classes):
        roc_auc = roc_auc_score(target_class_bin[:, i], y_prob_all[:, i])
        auc_scores.append(roc_auc)
        print(f"AUC ROC of {name} - Test: {class_name}: {roc_auc:.4f}")

    general_auc = np.mean(auc_scores)
    results[name] = general_auc
    print(f"General AUC ROC of {name} - Test: {general_auc:.4f}\n")

# הצגת התוצאות הסופיות לכל מסווג
print("\nFold-10 Results Summary:")
for name, auc in results.items():
    print(f"{name}: General AUC ROC: {auc:.4f}")

"""הרצה כעת בלי אובר-סמפלינג"""

import pandas as pd
from sklearn.model_selection import cross_val_score, StratifiedKFold, cross_val_predict
from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import label_binarize
import numpy as np

# הגדרת הפיצ'רים והמטרות
features = df_reduced_3.drop('age_group', axis=1)
target_class = df_reduced_3['age_group']

# בינאריזציה של היעדים לחישוב AUC לכל קטגוריה
classes = target_class.unique()
target_class_bin = label_binarize(target_class, classes=classes)

# הגדרת StratifiedKFold ל-Fold-10
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# מסווגים
classifiers = {
    "Decision Tree": DecisionTreeClassifier(max_depth=4, min_samples_leaf=15, random_state=1),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=200, random_state=42),
    "Naive Bayes": GaussianNB()
}

# אחסון התוצאות
results = {}

# ריצה על כל מסווג
for name, clf in classifiers.items():
    auc_scores = []
    y_prob_all = cross_val_predict(clf, features, target_class, cv=skf, method='predict_proba')

    for i, class_name in enumerate(classes):
        roc_auc = roc_auc_score(target_class_bin[:, i], y_prob_all[:, i])
        auc_scores.append(roc_auc)
        print(f"AUC ROC of {name} - Test: {class_name}: {roc_auc:.4f}")

    general_auc = np.mean(auc_scores)
    results[name] = general_auc
    print(f"General AUC ROC of {name} - Test: {general_auc:.4f}\n")

# הצגת התוצאות הסופיות לכל מסווג
print("\nFold-10 Results Summary:")
for name, auc in results.items():
    print(f"{name}: General AUC ROC: {auc:.4f}")